{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parte 1\n",
    "\n",
    "Ejercicio 1) Presentar 3 problemas de clasificacion, con su dataset, explique cual es la \n",
    "variable a clasificar y cuales son las variables que se utilizan para la clasificacion\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "a- Prestamo bancario\n",
    "El problema a subsanar es decidir si se le permite a un cliente sacar un prestamo\n",
    "Dataset: https://www.kaggle.com/datasets/bhavikjikadara/loan-status-prediction\n",
    "Variable a Clasificar: Estado del Préstamo\n",
    "Variables para la Clasificación: Casado, dependiente, educación, trabajador independiente, ingresos, ingreso garante, monto del préstamo, plazo, historial crediticio, zona de residencia\n",
    "\n",
    "b- Noticias Falsas\n",
    "El problema de clasificacion es ver si la noticia es falsa o no\n",
    "Dataset: https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n",
    "Variable a Clasificar: Label (0 = Falso; 1 = Verdadera)\n",
    "Variables para la Clasificación: Título, Texto.\n",
    "\n",
    "c- Animales\n",
    "El problema busca clasificar los animales en distintas claseṣ, en base a sus características\n",
    "Dataset: https://www.kaggle.com/datasets/agajorte/zoo-animals-extended-dataset\n",
    "Variable a Clasificar: Class_type\n",
    "Variables para la clasificación:hair, feathers, eggs, milk, airborne, aquatic, predator, toothed, backbone, breathes, venomous, fins, legs, tail, domestic, catsize\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejercicio 2) Investigar qué es un clasificador en IA y como funciona\n",
    "\n",
    "Un clasificador es un modelo, el cuál intenta prever la etiqueta correcta de unos datos de entrada dados. \n",
    "El proceso de entrenamiento de un clasificador implica introducir datos etiquetados en el modelo, lo que le permite aprender los patrones y las relaciones entre las características de entrada y las clases de destino. Luego, el modelo se evalúa en un conjunto separado de datos llamado conjunto de prueba para evaluar su desempeño al realizar predicciones precisas.\n",
    "\n",
    "Existen cuatro tareas principales de clasificación en machine learning:\n",
    "    • Clasificación Binaria: las entradas se clasifican en una de dos clases posibles. \n",
    "    • Clasificación Multiclase: las entradas se clasifican en una de más de dos clases posibles.\n",
    "    • Clasificación Multi Etiqueta: cada entrada puede pertenecer a más de una clase simultáneamente. Es decir, una entrada puede tener múltiples etiquetas.\n",
    "    • Clasificación Desequilibrada: el número de ejemplos se distribuye de forma desigual en cada clase, lo que significa que podemos tener más de una clase que de las demás en los datos de entrenamiento.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejercicio 3) Investigar métricas que se utilizan para elegir entre clasificadores.\n",
    "\n",
    "Las métricas más usadas para elegir un modelo de clasificación son:\n",
    "\n",
    "Accuracy (Exactitud): Es el porcentaje de predicciones correctas en relación con el total de predicciones realizadas. Se usa cuando las clases están balanceadas.\n",
    "\n",
    "Precisión (Precisión): Indica el porcentaje de predicciones positivas que son correctas. Es útil en casos donde el costo de los falsos positivos es alto.\n",
    "\n",
    "Recall (Sensibilidad o Tasa de Verdaderos Positivos): Mide la capacidad del modelo para identificar correctamente las instancias positivas. Es importante cuando el costo de los falsos negativos es alto.\n",
    "\n",
    "F1-Score: Es la media armónica de la precisión y el recall. Se utiliza cuando es importante tener un equilibrio entre la precisión y el recall.\n",
    "\n",
    "ROC-AUC (Receiver Operating Characteristic - Area Under the Curve): Representa el área bajo la curva ROC, que es una gráfica que muestra la relación entre la tasa de verdaderos positivos y la tasa de falsos positivos. Es útil para evaluar modelos con clases desbalanceadas.\n",
    "\n",
    "Log Loss (Pérdida Logarítmica): Mide el rendimiento de un modelo de clasificación basado en la probabilidad asignada a cada clase. Un valor más bajo indica un mejor rendimiento del modelo.\n",
    "\n",
    "Matriz de Confusión: Es una tabla que permite visualizar el rendimiento del algoritmo, mostrando las predicciones correctas e incorrectas desglosadas por cada clase.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejercicio 4) Investigar por qué se dividen los datos para entrenar los clasificadores, que es el sesgo y la varianza en contexto de IA?\n",
    "\n",
    " Dividir los datos para entrenar clasificadores en Machine Learning es una práctica fundamental que tiene varios propósitos clave:\n",
    "\n",
    "Evaluación Justa del Modelo\n",
    "Entrenamiento vs. Prueba: Al dividir los datos en conjuntos de entrenamiento y prueba, podemos entrenar el modelo en un conjunto de datos y luego evaluarlo en un conjunto separado que no ha visto durante el entrenamiento. Esto permite obtener una estimación imparcial y realista del rendimiento del modelo en datos nuevos y no vistos, lo que es crucial para evitar sobrestimar su capacidad predictiva.\n",
    "\n",
    "Prevención del Overfitting\n",
    "Sobre ajuste: Si se entrena y evalúa un modelo utilizando los mismos datos, es probable que el modelo aprenda patrones específicos de esos datos, incluidos el ruido o las peculiaridades que no generalizan bien a datos nuevos. Dividir los datos ayuda a detectar este problema de sobre ajuste, asegurando que el modelo no solo memorice el conjunto de entrenamiento, sino que generalice a datos nuevos.\n",
    "\n",
    "Selección y Ajuste de Hiper Parámetros\n",
    "Conjunto de Validación: Además de los conjuntos de entrenamiento y prueba, a veces se utiliza un tercer conjunto llamado conjunto de validación. Este conjunto se utiliza para ajustar los hiper parámetros del modelo (como la profundidad de un árbol de decisión o la tasa de aprendizaje en redes neuronales) sin afectar el conjunto de prueba. Esto permite optimizar el modelo mientras se mantiene un conjunto separado para la evaluación final.\n",
    "\n",
    "Generalización del Modelo\n",
    "Rendimiento en Datos Nuevos: El objetivo final de cualquier modelo de Machine Learning es que funcione bien en datos nuevos y no vistos. Al dividir los datos y realizar evaluaciones cruzadas, se puede obtener una idea más clara de cómo se comportará el modelo en la práctica, evitando sorpresas desagradables cuando se despliegue en producción.\n",
    "\n",
    "Estimación de Variabilidad\n",
    "Cross-Validation (Validación Cruzada): A veces, los datos se dividen en múltiples subconjuntos, y el modelo se entrena y evalúa múltiples veces (por ejemplo, en k-fold cross-validation). Esto proporciona una mejor estimación de la variabilidad del rendimiento del modelo y ayuda a garantizar que el rendimiento reportado no sea simplemente un caso atípico debido a una partición particular de los datos.\n",
    "\n",
    "Sesgo y Varianza\n",
    "\n",
    "El sesgo es la tendencia de un modelo de machine learning a hacer predicciones inexactas o injustas porque hay errores sistemáticos en el modelo de ML o en los datos utilizados para entrenar el modelo.\n",
    "El sesgo en el machine learning puede deberse a diversos factores. Algunas causas comunes incluyen:\n",
    "-  Datos de entrenamiento limitados\n",
    "-  Elección de un modelo de machine learning que no se adapta bien al problema o no tiene capacidad suficiente para captar la complejidad de los datos.\n",
    "-  Sesgo humano introducido en los procesos de recopilación de datos, etiquetado o asignación de atributos.\n",
    "\n",
    "La varianza hace referencia a cuánto cambia el modelo cuando se entrena con diferentes subconjuntos del mismo conjunto de datos. Un modelo con alta varianza se ajusta demasiado a los datos de entrenamiento, capturando no solo las tendencias generales, sino también el ruido o las fluctuaciones aleatorias en esos datos. Esto conduce a un problema conocido como overfitting (sobreajuste), donde el modelo tiene un excelente rendimiento en los datos de entrenamiento, pero falla al generalizar en nuevos datos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parte 2\n",
    "\n",
    "Investigar:\n",
    "\n",
    "1- Correlación entre caracteristicas y etiquetas\n",
    "\n",
    "Se refiere a la dependencia entre las features o caracteristicas de entrada\n",
    "y las etiquetas o labels de salida que nos da el modelo.\n",
    "En base a que tan relacionadas este cada característica con la etiqueta podemos\n",
    "dar por sentado que nos va a servir para entrenar el modelo.\n",
    "\n",
    "Si no existe correlacion alguna, lo único que estariamos haciendo\n",
    "al incluir esa característica, seria agregar ruido al modelo.\n",
    "\n",
    "Gracias a esta correlacion podemos elegir que características o features\n",
    "incluir. Siendo estas las más relevantes para el modelo.\n",
    "\n",
    "- Puede existir una correlacion positiva (Cuando una feature aumenta, aumenta la probabilidad que pertenezca a una clase específica)\n",
    "- Tambíen una correlacion negativa (Cuando disminuye el valor de la feature, es menos probable que pertenezca a una etiqueta específica)\n",
    "\n",
    "\n",
    "2 - Random Forest\n",
    "\n",
    "Es un algoritmo de aprendizaje automático versátil que funciona mediante la construcción de múltiples árboles de decisión durante el entrenamiento y la generación de la moda de las clases (clasificación) o la predicción media (regresión) de los árboles individuales\n",
    "Random Forest es especialmente adecuado para la selección de características por varias razones:\n",
    "    • Clasificación de características intrínsecas: Random Forest proporciona un método integrado para evaluar la importancia de las características.\n",
    "    • Maneja alta dimensionalidad: eficaz incluso cuando el número de características es mucho mayor que el número de muestras.\n",
    "    • No linealidad: puede capturar interacciones complejas entre características sin requerir una especificación explícita de las interacciones.\n",
    "\n",
    "Beneficios de Random Forest\n",
    "\n",
    "Riesgo reducido de sobreajuste: Los árboles de decisión corren el riesgo de sobre ajustarse, ya que tienden a ajustarse de manera muy precisa a todas las muestras dentro de los datos de entrenamiento. Sin embargo, cuando se tiene un número robusto de árboles de decisión en un bosque aleatorio, el clasificador no sobre ajustará el modelo, ya que el promedio de árboles no correlacionados reduce la varianza total y el error de predicción.\n",
    "Proporciona flexibilidad: Dado que el bosque aleatorio puede manejar tareas tanto de regresión como de clasificación con un alto grado de precisión, es un método popular entre los científicos de datos. La técnica de \"feature bagging\" también hace que el clasificador de bosque aleatorio sea una herramienta efectiva para estimar valores faltantes, ya que mantiene la precisión cuando falta una parte de los datos.\n",
    "Fácil de determinar la importancia de las características: Facilita la evaluación de la importancia de las variables, o su contribución al modelo. Existen varias maneras de evaluar la importancia de las características. La importancia de Gini y la disminución media en la impureza (MDI) suelen utilizarse para medir cuánto disminuye la precisión del modelo cuando se excluye una variable determinada. Sin embargo, la importancia de la permutación, también conocida como disminución media en la precisión (MDA), es otra medida de importancia. La MDA identifica la disminución media en la precisión al permutar aleatoriamente los valores de las características en las muestras fuera de bolsa (oob).\n",
    "\n",
    "3 - Métodos de eliminación recursiva de características (RFE)\n",
    "Es un algoritmo de optimización que busca encontrar el subconjunto de funciones con mejor rendimiento. Crea repetidamente modelos y deja de lado la mejor o la peor característica de rendimiento en cada iteración. Construye el siguiente modelo con las características de la izquierda hasta que se agotan todas las características, luego clasifica las características según el orden de su eliminación.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
